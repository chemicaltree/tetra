<?xml version="1.0" encoding="UTF-8"?>
<doc id="P12-1089" editor="A" format="Conf" position="NS" region="NN">
    <title>
        <text>Discriminative Learning for Joint Template Filling</text>
    </title>
    <abstract>
        <text>This paper presents a joint model for template filling, where the goal is to automatically specify the fields of target relations such as seminar announcements or corporate acquisition events. The approach models mention detection, unification</text>
        <edit type="grammar" crr="," comments="adding serial comma. Even if the style doesn't require it, in this case it's needed for disambiguation"></edit>
        <text>and field extraction in a flexible, feature-rich model that allows for joint modeling of interdependencies at all levels and across fields. Such an approach can, for example, learn likely event durations and the fact that start times should come before end times. While the joint inference space is large, we demonstrate effective learning with a</text>
        <edit type="capitalization" crr="perceptron-style" comments="capitalization - perceptron is typically not used as a proper noun">Perceptron-style</edit>
        <text>approach that uses simple, greedy beam decoding. Empirical results in two benchmark domains demonstrate consistently strong performance on both mention detection and template-filling tasks.</text>
    </abstract>   
    <introduction>
        <text>Information extraction (IE) systems recover structured information from text. Template filling is an IE task where the goal is to populate the fields of a target relation, for example to extract the attributes of a job posting (Califf and Mooney, 2003) or to recover the details of a corporate acquisition event from a news story (Freitag and McCallum, 2000).</text>
        <text>\\ This task is challenging due to the wide range of cues from the input documents, as well as non-textual background knowledge, that must be considered to find the best joint assignment for the fields of the extracted relation. For example, Figure 1 shows an extraction from</text>
        <edit type="grammar" crr="the" comments="grammar - missing article"></edit>
        <text>CMU seminar announcement corpus (Freitag and McCallum, 2000). Here, the goal is to perform mention detection and extraction</text>
        <edit type="grammar" crr="" comments="comma not needed before prepositional phrase">,</edit>
        <text>by finding all of the text spans, or mentions, that describe field values,</text>
        <edit type="parallelism" crr="unifying" comments="parallelism - making the form of the list items the same">unify</edit>
        <text>these mentions by grouping them according to target field, and normalizing the results within each group to provide the final extractions. Each of these steps requires significant knowledge about the target relation. For example, in Figure 1, the mention “3:30” appears three times and provides the only reference to a time. We must infer that this is the starting time, that the end time is never explicitly mentioned, and also that the event is in the afternoon. Such inferences may not hold in more general settings, such as extraction for medical emergencies or</text>
        <edit type="clarity;punctuation" crr="events that are related to each other." comments="">related events</edit>
        <text>\\ In this paper, we present a joint modeling and learning approach for the combined tasks of mention detection, unification, and template filling, as described above. As we will see in Section 2, previous work has mostly focused on learning tagging models for mention detection, which can be difficult to aggregate into a full template extraction, or directly learning template field value extractors, often in isolation and with no reasoning across different fields in the same relation. We present a simple, feature-rich, discriminative model that readily incorporates a broad range of possible constraints on the mentions and joint field assignments.</text>
        <text>\\ ed model to weight the different extraction options, including</text>
        <edit type="punctuation" crr=", for example," comments="punctuation - for example is typically set off by commas or semicolon/comma">for example</edit>
        <text>the likely lengths for events</text>
        <edit type="punctuation" crr="" comments="punctuation - comma not needed in list of two.">,</edit>
        <text>or the fact that start times should come before end times. However, there are significant</text>
        <edit type="word choice" crr="computational" comments="word choice - using the adjective form here">computation</edit>
        <text>challenges that come with this style of joint learning. We demonstrate empirically that these challenges can be solved with a combination of greedy beam decoding, performed directly in the joint space of possible mention clusters and field assignments, and</text>
        <edit type="grammar" crr="a" comments="grammar - missing article."></edit>
        <text>structured</text>
        <edit type="capitalization" crr="perceptron-style" comments="capitalization - perceptron is typically not used as a proper noun">Perceptron-style</edit>
        <text>learning algorithm (Collins, 2002).</text>
        <text>\\ We report experimental evaluations on two benchmark datasets in different genres, the CMU seminar announcements and corporate acquisitions (Freitag and McCallum, 2000). In each case, we evaluated both template extraction and mention detection performance. Our joint learning approach provides consistently strong results across every setting, including new state-of-the-art results. We also demonstrate, through ablation studies on the feature set, the need for joint modeling and the relative importance of the different types of joint constraints.</text>
    </introduction>   
</doc>