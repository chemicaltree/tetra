<?xml version="1.0" encoding="UTF-8"?>
<doc id="W09-2101" editor="A" format="WS" position="nS" region="N">
    <title>
        <text>Automatic Assessment of Spoken Modern Standard Arabic</text>
    </title>
    <abstract>
        <text>Proficiency testing is an important ingredient in successful language teaching. However, repeated testing for course placement, over the course of instruction or for certification</text>
        <edit type="punctuation" crr="," comments="punctuation - missing comma at end of nonrestrictive clause"></edit>
        <text>can be time-consuming and costly. We present the design and validation of the Versant Arabic Test, a fully automated test of spoken Modern Standard Arabic, that evaluates test-takers' facility in listening and speaking. Experimental data shows the test to be highly reliable (test-retest r=0.97) and to strongly predict performance on the ILR OPI (r=0.87), a standard interview test that assesses oral proficiency.</text>
    </abstract>   
    <introduction>
        <text>Traditional high-stakes testing of spoken proficiency often evaluates the test-taker's ability to accomplish communicative tasks in a conversational setting. For example, learners may introduce themselves, respond to requests for information, or accomplish daily tasks in a role-play.</text>
        <text>\\ Testing oral proficiency in this way can be time-consuming and costly, since at least one trained interviewer is needed for each student. For example, the standard oral proficiency test used by</text>
        <edit type="grammar" crr="" comments="grammar - don't need the article here since we're talking about generic government agencies">the</edit>
        <text>United States government agencies (the Interagency Language Roundtable Oral Proficiency Interview or ILR OPI) is usually administered by two certified interviewers for approximately 30-45 minutes per candidate</text>
        <text>\\ The great effort involved in oral proficiency interview (OPI) testing makes automated testing an attractive alternative. Work has been reported on fully automated scoring of speaking ability (e.g., Bernstein and Barbier, 2001; Zechner et al., 2007, for English; Balogh and Bernstein, 2007, for English and Spanish). Automated testing systems do not aim to simulate a conversation with the test-taker and therefore do not directly observe interactive human communication. Bernstein and Barbier (2001) describe a system that might be used in qualifying simultaneous interpreters; Zechner et al. (2007) describe an automated scoring system that assesses performance according to the TOEFL iBT speaking rubrics. Balogh and Bernstein (2007) focus on evaluating facility in a spoken language, a separate test construct that relates to oral proficiency.</text>
        <text>\\ “Facility in a spoken language” is defined as “the ability to understand a spoken language on everyday topics and to respond appropriately and intelligibly at a native-like conversational pace” (Balogh and Bernstein, 2007, p. 272). This ability is assumed to underlie high performance in communicative settings, since learners have to understand their interlocutors correctly and efficiently in real time to be able to respond. Equally, learners have to be able to formulate and articulate a comprehensible answer without undue delay. Testing for oral proficiency, on the other hand, conventionally includes additional aspects such as correct interpretation of the pragmatics of the conversation, socially and culturally appropriate wording, and content and knowledge of the subject matter under discussion.</text>
        <text>\\  In this paper, we describe the design and validation of the Versant Arabic Test (VAT), a fully automated test of facility with spoken Modern Standard Arabic (MSA). Focusing on facility rather than communication-based oral proficiency enables the creation of an efficient yet informative automated test of listening and speaking ability. The automated test can be administered over the telephone or on a computer in approximately 17 minutes. Despite its much shorter format and constrained tasks, test-taker scores on the VAT strongly correspond to their scores from an ILR Oral Proficiency Interview.</text>
        <text>\\ The paper is structured as follows: After reviewing related work, we describe Modern Standard Arabic and introduce the test construct (i.e., what the test is intended to measure) in detail (Section 3). We then describe the structure and development of the VAT in Section 4 and present evidence for its reliability and validity in Section 5.</text>
    </introduction>   
</doc>