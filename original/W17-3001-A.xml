<?xml version="1.0" encoding="UTF-8"?>
<doc id="W17-3001" editor="A" format="WS" position="S" region="N">
    <title>
        <text>Dimensions of Abusive Language on Twitter</text>
    </title>
    <abstract>
        <text>In this paper, we use a new categorical form of multidimensional register analysis to identify the main dimensions of functional linguistic variation in a corpus of abusive language</text>
        <edit type="flow" crr="" comments="flow - it's not wrong to have this comma here, but it feels choppy in this case">,</edit>
        <text>consisting of racist and sexist</text>
        <edit type="capitalization" crr="tweets." comments="capitalization - usage in OED and MW have this as lowercase">Tweets.</edit>
        <text>By analysing the use of a wide variety of parts-of-speech and grammatical constructions</text>
        <edit type="punctuation" crr="" comments="punctuation - comma not needed before 'as well as'">,</edit>
        <text>as well as various features related to Twitter and computer-mediated communication, we discover three dimensions of linguistic variation in this corpus, which we interpret as being related to the degree of interactive, antagonistic, and attitudinal language exhibited by individual tweets. We then demonstrate that there is a significant functional difference between racist and sexist tweets, with</text>
        <edit type="spelling" crr="sexist" comments="spelling - looks like just a stray s">sexists</edit>
        <text>tweets tending to be more interactive and attitudinal than racist tweets.</text>
    </abstract>   
    <introduction>
        <text>With the rise of trolling and other forms of abusive language online, many computational methods for detecting abusive language have been introduced. These classifiers have been trained on a wide range of linguistic features, including specific keywords (Xiang et al., 2012), Bag-of-Words (Warner and Hirschberg, 2012), character n-grams (Mehdad and Tetreault, 2016), word n-grams (Chen et al., 2012; Yin et al., 2009), part-of-speech n-grams (Davidson et al., 2017), and various syntactic features (Burnap and Williams, 2014). A variety of extra-linguistic features have also been considered, including gender (Waseem and Hovy, 2016), location (Waseem and Hovy, 2016), user behaviour and performance (Balci and Salah, 2015; Dadvar et al., 2013), and surrounding posts (Yin et al., 2009). Many of these methods assume that abusive language includes profanity and negative sentiment, but such features are not always present in abusive posts. Including offensive terms in the feature set can even hinder the accuracy of classifiers (Davidson et al., 2017), because profanity can be used for amplification and other non-abusive functions, leading to many false positives (Chen et al., 2012). Trolls have also developed more covert ways of abusing others, such as using creative spelling or avoiding offensive words (Hine et al., 2017). These strategies have been accounted for in part by examining the use of offensive words in context, applying spell-correction algorithms (Chen et al., 2012), consulting WordNet (Chen et al., 2012), and using character n-grams to deal with the noisiness of online communication (Mehdad and Tetreault, 2016).</text>
        <text>\\ Despite this growing body of research, functional variation in abusive language has yet to be investigated directly. At the most basic level, we do not know</text>
        <edit type="readability" crr="" comments="readability - this is awkward here. One solution would be to move the 'is' to the end of the sentence, but I think the sentence reads better and is perhaps even clearer without it.">what is</edit>
        <text>the general repertoire of styles for abusive language that exists online. One way to understand how the structure of language varies depending on its communicative purpose is</text>
        <edit type="hyphenation;consistency" crr="multi dimensional analysis" comments="hyphenation and consistency - multi- doesn't need hyphen unless result is confusing. this can be style specific, but author uses it without hyphen elsewhere in the text">multi-dimensional analysis</edit>
        <text>(MDA) (Biber, 1988, 1989). MDA is generally based on the relative frequencies of many lexical and grammatical features measured across a corpus of texts representing a particular variety of language. The most important dimensions of linguistic variation are extracted from this dataset through a factor analysis</text>
        <edit type="punctuation" crr="" comments="punctuation - comma is not needed here as what follows is not a full sentence">,</edit>
        <text>and then interpreted functionally based on the linguistic features and the individual texts that are most strongly associated with each dimension. In addition to providing a more complete understanding of the structure of abusive language, incorporating this type of information into abusive language classification systems should lead to more robust and principled methods.</text>
        <text>\\ The goal of this study is therefore to use MDA to identify the main dimensions of functional linguistic variation in a corpus of racist and sexist abusive tweets (Waseem and Hovy, 2016). However, because MDA relies on the multivariate analysis of the relative frequencies of linguistic features, it is not suitable for analysing a corpus of tweets, which typically include fewer than 30 words, and are therefore too short to allow for the relative frequencies of most features to be measured accurately. Rather than concatenate tweets to form longer texts</text>
        <edit type="grammar" crr="(e.g.," comments="e.g. always takes a comma">(e.g.</edit>
        <text>Passonneau et al., 2014), for example, by author, which would obscure text-level patterns, we</text>
        <edit type="word choice" crr="" comments="therefore doesn't fit here, there's not a good contrast before it">therefore</edit>
        <text>apply a new form of categorical MDA based on a multiple correspondence analysis of the simple occurrence of a variety of lexical and grammatical forms in individual tweets to identify common patterns of functional variation in abusive tweets. Finally, we investigate the degree to which the racist and sexist tweets in our corpus vary in terms of these dimensions.</text>
    </introduction>   
</doc>