<?xml version="1.0" encoding="UTF-8"?>
<doc id="W17-3001" editor="C" format="WS" position="S" region="N">
    <title>
        <text>Dimensions of Abusive Language on Twitter</text>
    </title>
    <abstract>
        <text>In this paper, we use a new categorical form of multidimensional register analysis to identify the main dimensions of</text>
        <edit type="hyphenation" crr="functional-linguistic" comments="hyphenate when qualifying noun that follows">functional linguistic</edit>
        <text>variation in a corpus of abusive language</text>
        <edit type="clarity" crr="that consists" comments="">, consisting</edit>
        <text>of racist and sexist Tweets. By analysing the use of a wide variety of parts-of-speech and grammatical constructions, as well as various features related to Twitter and computer-mediated communication, we discover three dimensions of linguistic variation in this corpus, which we interpret as being related to the degree of interactive, antagonistic</text>
        <edit type="grammar" crr="," comments="punctuation / list"></edit>
        <text>and attitudinal language exhibited by individual Tweets. We then demonstrate that there is a significant functional difference between racist and sexist Tweets, with</text>
        <edit type="grammar" crr="sexist" comments="">sexists</edit>
        <text>Tweets tending to be more interactive and attitudinal than racist Tweets.</text>
    </abstract>   
    <introduction>
        <text>With the rise of trolling and other forms of</text>
        <edit type="word choice" crr="online language abuse" comments="">abuseive language online</edit>
        <text>, many computational methods for detecting abusive language have been introduced. These classifiers have been trained on a wide range of linguistic features, including specific keywords (Xiang et al., 2012), Bag-of-Words (Warner and Hirschberg, 2012), character n-grams (Mehdad and Tetreault, 2016), word ngrams (Chen et al., 2012; Yin et al., 2009), part-of-speech n-grams (Davidson et al., 2017), and various syntactic features (Burnap and Williams, 2014). A variety of extra-linguistic features have also been considered, including gender (Waseem and Hovy, 2016), location (Waseem and Hovy, 2016), user behaviour and performance (Balci and Salah, 2015; Dadvar et al., 2013), and surrounding posts (Yin et al., 2009). Many of these methods assume that abusive language includes profanity and negative sentiment, but such features are not always present in abusive posts. Including offensive terms in the feature set can even hinder the accuracy of classifiers (Davidson et al., 2017), because profanity can be used for amplification and other non-abusive functions, leading to many false positives (Chen et al., 2012). Trolls have also developed more covert ways of abusing others, such as</text>
        <edit type="word choice;clarity" crr="the use of" comments="replace to clarify meaning">using</edit>
        <text>creative spelling or</text>
        <edit type="word choice" crr="the avoidance of" comments="">avoiding</edit>
        <text>offensive words (Hine et al., 2017). These strategies have been accounted for in part by examining the use of offensive words in context, applying spell-correction algorithms (Chen et al., 2012), consulting WordNet (Chen et al., 2012), and using character n-grams to deal with the noisiness of online communication (Mehdad and Tetreault, 2016).</text>
        <text>\\ Despite this growing body of research, functional variation in abusive language has yet to be investigated directly. At the most basic level, we</text>
        <edit type="style;conciseness" crr="are not familiar with" comments="Style / consider alternative to reduce wordiness">do not know what is</edit>
        <text>the general repertoire of</text>
        <edit type="clarity;conciseness" crr="online abusive language styles." comments="">for abusive language that exists online.</edit>
        <edit type="flow" crr="Multi-dimensional analysis (MDA) is one way of understanding how the structure of language can vary depending on its communicative purpose (Biber, 1988, 1989)." comments="Rephrase to improve flow">One way to understand how the structure of language varies depending on its communicative purpose is multi-dimensional analysis (MDA) (Biber, 1988, 1989).</edit>
        <text>MDA is generally based on the relative frequencies of many lexical and grammatical features measured across a corpus of texts that represent  a particular variety of language. The most important dimensions of linguistic variation are extracted from this dataset through a factor analysis, and then interpreted functionally, based on the linguistic features and the individual texts that are most strongly associated with each dimension. In addition to providing a more complete understanding of the structure of abusive language, incorporating this type of information into abusive language classification systems should lead to a more robust and principled methodology.</text>
        <text>\\ The goal of this study is therefore to use MDA</text>
        <edit type="repetitiveness" crr="for identifining" comments="consider replacing to avoid repetition of 'to'">to identify</edit>
        <text>the main dimensions of functional linguistic variation in a corpus of racist and sexist abusive tweets (Waseem and Hovy, 2016). However, because MDA relies on the multivariate analysis of the relative frequencies of linguistic features, it is not suitable for analysing a corpus of Tweets, which typically include fewer than 30 words, and are therefore too short to allow for the relative frequencies of most features to be measured accurately. Rather than concatenate Tweets to form longer texts (e.g. Passonneau et al., 2014), for example by author, which would obscure text-level patterns, we therefore apply a new form of categorical MDA</text>
        <edit type="clarity" crr="that is" comments=""></edit>
        <text>based on a multiple correspondence analysis of the simple occurrence of a variety of lexical and grammatical forms in individual Tweets to identify common patterns of functional variation in abusive Tweets. Finally, we investigate the degree to which the racist and sexist Tweets in our corpus vary in terms of these dimensions.</text>
    </introduction>   
</doc>