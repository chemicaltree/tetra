<?xml version="1.0" encoding="UTF-8"?>
<doc id="W16-0501" editor="A" format="WS" position="S" region="N">
    <title>
        <text>The Effect of Multiple Grammatical Errors on Processing</text>
        <edit type="hyphenation" crr="Nonnative" comments="hyphenation - nonnative is closed in MW Unabridged">Non-Native</edit>
        <text>Writing</text>        
    </title>
    <abstract>
        <text>In this work, we estimate the deterioration of NLP processing</text>
        <edit type="clarity" crr="accuracy" comments="clarity - we need to say what about the processing deteriorates - speed? resource consumption, accuracy? From discussion below I think it's accuracy but I'd want to see the full paper to confirm."></edit>
        <text>given an estimate of the</text>
        <edit type="word choice" crr="number" comments="word choice - Number is used when it's countable, amount when it's a mass amount - amount of rain, number of apples">amount</edit>
        <text>and nature of grammatical errors in a text. From a corpus of essays written by English-language learners, we extract ungrammatical sentences, controlling the number and types of errors in each sentence. We focus on six categories of errors that are commonly made by English-language learners</text>
        <edit type="punctuation" crr="" comments="punctuation - comma not appropriate here">,</edit>
        <text>and consider sentences containing one or more of these errors. To evaluate the effect of grammatical errors, we measure the deterioration of ungrammatical dependency parses using the labeled F-score, an adaptation of the labeled attachment score. We find notable differences between the influence of individual error types</text>
        <edit type="clarity;readability" crr="as well as multiple co-occuring errors, on the dependency parse" comments="clarity and readability - with the phrase at the end as in the original, it's not totally clear what the 'as well as' ties to, making the sentence difficult to parse.">on the dependency parse, as well as interactions between multiple errors</edit>
    </abstract>   
    <introduction>
        <text>With the large number of English-language learners and the prevalence of informal web text, noisy text containing grammatical errors is widespread. However, the majority of NLP tools are developed and trained over clean, grammatical text</text>
        <edit type="punctuation" crr="," comments="punctuation - comma needed before conjunction followed by independent clause"></edit>
        <text>and the performance of these tools may be negatively affected when processing errorful text. One possible workaround is to adapt tools for noisy text,</text>
        <edit type="punctuation" crr="e.g.," comments="punctuation, comma needed after e.g.">e.g.</edit>
        <text>(Foster et al., 2008; Cahill et al., 2014). However, it is often preferable to use tools trained on clean text, mainly because of the resources necessary for training and the limited availability of large-scale annotated corpora, but also because tools should work correctly in the presence of well-formed text.</text>
        <text>\n\n Our goal is to measure the performance degradation of an automatic NLP task based on an estimate of</text>
        <edit type="clarity" crr="the number and types of" comments="clarity - need to specify what aspect of the errors we're estimating. I'd want to see the whole paper to confirm that this is the correct wording."></edit>
        <text>grammatical errors in a text. For example, if we are processing student responses within an NLP application</text>
        <edit type="punctuation" crr="" comments="punctuation - comma is not appropriate here since this is a list of two items following the 'if'">,</edit>    
        <text>and the responses contain a mix of native and</text>
        <edit type="hyphenation" crr="nonnative" comments="hyphenation - nonnative is closed in MW Unabridged">non-native</edit>
        <text>texts, it would be useful to be able to estimate the difference in performance (if any) of the NLP application</text>
        <edit type="word choice" crr="between" comments="word choice: 'difference ... between', not 'difference ... on'">on</edit>
        <text>both types of texts.</text>
        <text>\n\n  We choose dependency parsing as our prototypic task because it is often one of the first complex downstream tasks in NLP pipelines. We will consider six common grammatical errors made by nonnative</text>        
        <edit type="readability;conciseness" crr="English speakers" comments="">speakers of English</edit>
        <text>and systematically control the number and types of errors present in a sentence. As errors are introduced to a sentence, the degradation of the dependency parse is measured by the decrease in the F-score over dependency relations.</text>
        <text>\n\n In this work, we will show that</text>
        <text>\n increasing the number of errors in a sentence decreases the accuracy of the dependency parse (Section 4.1);</text>
        <text>\n the distance between errors does not affect the accuracy (Section 4.2);</text>
        <edit type="style" crr="and" comments="missing word - lists formatted as part of sentence should contain the conjunctions as if it were written in normal sentence form."></edit>
        <text>\n some types of grammatical errors have a greater impact, alone or in combination with other errors (Section 4.3).</text>
        <text>While these findings may seem self-evident, they have not previously been quantified on a large corpus of naturally occurring errors. Our analysis will serve as the first step to understanding what happens to</text>
        <edit type="word choice" crr="an NLP" comments="word choice - 'an' is needed as this is typically read and pronounced as 'en ell pea', starting with the vowel.">a NLP</edit>
        <text>pipeline when confronted with grammatical errors.</text>      
    </introduction>   
</doc>